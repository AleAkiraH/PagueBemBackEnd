# ğŸ¤– Copilot Instructions â€” PadrÃ£o de Projetos AWS com Terraform

> **Este documento Ã© vivo.** Ele evolui conforme o projeto cresce. O agente deve consultÃ¡-lo sempre
> que receber uma solicitaÃ§Ã£o e propor atualizaÃ§Ãµes quando novos padrÃµes forem estabelecidos.

---

## ğŸ“Œ VisÃ£o Geral

Eu trabalho com projetos que usam **infraestrutura AWS gerenciada por Terraform**, com **ambientes separados (dev/prod)** e **repositÃ³rios independentes por recurso AWS**. Todos os repos sÃ£o reunidos em um Ãºnico **VS Code Workspace** para facilitar o desenvolvimento.

### Filosofia Central

1. **1 recurso AWS = 1 repositÃ³rio Terraform** (isolamento total)
2. **dev e prod sempre separados** com `terraform.tfvars` prÃ³prios
3. **Deploy e Destroy devem funcionar perfeitamente** â€” sem lixo na AWS
4. **State remoto no S3** com lock no DynamoDB para seguranÃ§a
5. **Frontend separado** com deploy na Vercel (ou similar)
6. **Tudo deve ser destruÃ­vel** â€” `terraform destroy` precisa limpar 100% dos recursos

---

## ğŸ—ï¸ Arquitetura do Workspace

```
ğŸ“ C:\GIT\{nome-projeto}\                    â† Frontend + workspace config
ğŸ“ C:\GIT\{nome-projeto}-terraform\           â† Todos os repos Terraform (multi-root workspace)
    â”œâ”€â”€ ğŸ“ dynamodb\                          â† Tabelas DynamoDB
    â”œâ”€â”€ ğŸ“ lambda\                            â† Lambda Functions + cÃ³digo fonte
    â”œâ”€â”€ ğŸ“ apigateway\                        â† API Gateway HTTP
    â”œâ”€â”€ ğŸ“ s3\                                â† Buckets S3 (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ sqs\                               â† Filas SQS (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ cognito\                           â† Cognito User Pools (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ sns\                               â† SNS Topics (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ eventbridge\                       â† EventBridge Rules (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ cloudfront\                        â† CloudFront Distributions (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ rds\                               â† RDS/Aurora (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ ecs\                               â† ECS/Fargate (se necessÃ¡rio)
    â”œâ”€â”€ ğŸ“ stepfunctions\                     â† Step Functions (se necessÃ¡rio)
    â””â”€â”€ ğŸ“ iam\                               â† Roles/Policies compartilhadas (se necessÃ¡rio)
```

### Workspace File (.code-workspace)

O arquivo `.code-workspace` fica no repositÃ³rio do **frontend** e referencia todos os repos:

```json
{
  "folders": [
    { "path": "." },
    { "path": "../{nome-projeto}-terraform/apigateway" },
    { "path": "../{nome-projeto}-terraform/dynamodb" },
    { "path": "../{nome-projeto}-terraform/lambda" }
  ]
}
```

---

## ğŸ“ Estrutura PadrÃ£o de Cada RepositÃ³rio Terraform

Todo repositÃ³rio de recurso AWS **DEVE** seguir esta estrutura:

```
{recurso}/
â”œâ”€â”€ main.tf                     â† Recursos Terraform
â”œâ”€â”€ variables.tf                â† VariÃ¡veis com validaÃ§Ã£o
â”œâ”€â”€ outputs.tf                  â† Outputs para outros mÃ³dulos consumirem
â”œâ”€â”€ README.md                   â† DocumentaÃ§Ã£o com deploy, destroy e dependÃªncias
â”œâ”€â”€ .gitignore                  â† Ignorar .terraform/, *.tfstate, *.tfplan, etc.
â”œâ”€â”€ .terraform.lock.hcl         â† Lock do provider (versionado)
â”œâ”€â”€ dev/
â”‚   â”œâ”€â”€ terraform.tfvars        â† Valores reais de dev (âš ï¸ pode conter secrets, NÃƒO versionar)
â”‚   â””â”€â”€ terraform.tfvars.example â† Template de exemplo (versionado)
â”œâ”€â”€ prod/
â”‚   â”œâ”€â”€ terraform.tfvars        â† Valores reais de prod (âš ï¸ NÃƒO versionar)
â”‚   â””â”€â”€ terraform.tfvars.example â† Template de exemplo (versionado)
â””â”€â”€ .github/                    â† (opcional) CI/CD workflows
```

### Se o recurso contÃ©m cÃ³digo-fonte (ex: Lambda):

```
lambda/
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â”œâ”€â”€ README.md
â”œâ”€â”€ dev/ e prod/                â† tfvars
â””â”€â”€ lambda/                     â† CÃ³digo-fonte da aplicaÃ§Ã£o
    â”œâ”€â”€ main.py                 â† Handler principal
    â”œâ”€â”€ Dockerfile              â† Build da imagem Docker
    â”œâ”€â”€ requirements.txt        â† DependÃªncias Python
    â”œâ”€â”€ controller/             â† Controllers (routing/parsing)
    â”œâ”€â”€ services/               â† LÃ³gica de negÃ³cio
    â”œâ”€â”€ repository/             â† Acesso a dados (DynamoDB)
    â”œâ”€â”€ models/                 â† Modelos de domÃ­nio
    â”œâ”€â”€ dtos/                   â† ValidaÃ§Ã£o com Pydantic
    â””â”€â”€ utils/                  â† JWT, logging, exceptions
```

---

## ğŸ”§ PadrÃ£o do main.tf

Todo `main.tf` **DEVE** conter:

```hcl
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }

  backend "s3" {
    bucket         = "{nome-projeto}-terraform-state"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
    # key Ã© passado via -backend-config="key=..." no terraform init
    # Dev:  {recurso}/dev/terraform.tfstate
    # Prod: {recurso}/prod/terraform.tfstate
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Environment = var.environment
      Project     = var.project_name
      ManagedBy   = "Terraform"
      Repository  = "{nome-projeto}-terraform-{recurso}"
    }
  }
}
```

### Regras obrigatÃ³rias:

- **Backend S3**: Bucket `{nome-projeto}-terraform-state` com DynamoDB `terraform-locks`
- **State separado por ambiente**: key segue padrÃ£o `{recurso}/{env}/terraform.tfstate`
- **Default Tags**: SEMPRE incluir `Environment`, `Project`, `ManagedBy`, `Repository`
- **Nomes de recursos**: padrÃ£o `{nome-projeto}-{descritivo}-{environment}` (ex: `controlese-api-dev`)

---

## ğŸ”§ PadrÃ£o do variables.tf

Toda `variables.tf` **DEVE** conter ao menos:

```hcl
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "environment" {
  description = "Environment (dev, prod)"
  type        = string
  validation {
    condition     = contains(["dev", "prod"], var.environment)
    error_message = "Environment must be 'dev' or 'prod'."
  }
}

variable "project_name" {
  description = "Project name"
  type        = string
  default     = "{nome-projeto}"
}
```

---

## ğŸ”§ PadrÃ£o do outputs.tf

Outputs devem expor **tudo que outros mÃ³dulos possam precisar**:

- **DynamoDB**: `table_name`, `table_arn` para cada tabela
- **Lambda**: `function_name`, `function_arn`, `role_arn`, `ecr_repository_url`
- **API Gateway**: `api_endpoint`, `api_id`, `api_execution_arn`, `stage_name`
- **S3**: `bucket_name`, `bucket_arn`
- **SQS**: `queue_url`, `queue_arn`
- **SNS**: `topic_arn`

---

## ğŸ”§ PadrÃ£o do .gitignore (Terraform repos)

```gitignore
# Terraform
.terraform/
terraform.tfstate
terraform.tfstate.*
*.tfplan
*.tfstate.backup
crash.log
override.tf
override.tf.json
*_override.tf
*_override.tf.json

# Secrets
.env
.env.local
.env.*.local

# NÃƒO versionar tfvars com secrets reais
# dev/terraform.tfvars   â† contÃ©m ARNs e secrets
# prod/terraform.tfvars  â† contÃ©m ARNs e secrets

# Python (se aplicÃ¡vel)
__pycache__/
*.py[cod]
*.egg-info/
.venv/
venv/
build/
dist/

# IDE
.vscode/
.idea/
```

---

## ğŸš€ Comandos de Deploy e Destroy

### Ordem de Deploy (IMPORTANTE â€” respeitar dependÃªncias)

```
1ï¸âƒ£  dynamodb     â†’ Sem dependÃªncias (criar primeiro)
2ï¸âƒ£  s3           â†’ Sem dependÃªncias (se usado)
3ï¸âƒ£  sqs          â†’ Sem dependÃªncias (se usado)
4ï¸âƒ£  lambda       â†’ Depende de: dynamodb (ARNs), sqs (ARNs, se usado)
5ï¸âƒ£  apigateway   â†’ Depende de: lambda (ARN e nome da funÃ§Ã£o)
6ï¸âƒ£  cloudfront   â†’ Depende de: s3 e/ou apigateway (se usado)
7ï¸âƒ£  frontend     â†’ Depende de: apigateway (endpoint URL)
```

### Ordem de Destroy (INVERSA do deploy)

```
7ï¸âƒ£  frontend     â†’ Remover deploy da Vercel
6ï¸âƒ£  cloudfront   â†’ Destroy primeiro (se usado)
5ï¸âƒ£  apigateway   â†’ terraform destroy -var-file="{env}/terraform.tfvars"
4ï¸âƒ£  lambda       â†’ terraform destroy -var-file="{env}/terraform.tfvars"
3ï¸âƒ£  sqs          â†’ terraform destroy -var-file="{env}/terraform.tfvars" (se usado)
2ï¸âƒ£  s3           â†’ terraform destroy -var-file="{env}/terraform.tfvars" (se usado)
1ï¸âƒ£  dynamodb     â†’ terraform destroy -var-file="{env}/terraform.tfvars"
```

### Comandos para cada recurso:

```powershell
# ===== INIT (primeira vez ou troca de ambiente) =====
terraform init -backend-config="key={recurso}/{env}/terraform.tfstate"

# Exemplo para dynamodb em dev:
terraform init -backend-config="key=dynamodb/dev/terraform.tfstate"

# ===== PLAN (visualizar mudanÃ§as) =====
terraform plan -var-file="{env}/terraform.tfvars"

# ===== APPLY (deploy) =====
terraform apply -var-file="{env}/terraform.tfvars"

# ===== DESTROY (remover tudo) =====
terraform destroy -var-file="{env}/terraform.tfvars"
```

---

## ğŸ§¹ Regras de Limpeza Total (Zero Lixo na AWS)

Para garantir que `terraform destroy` remove TUDO:

1. **ECR**: usar `force_delete = true` no `aws_ecr_repository`
2. **S3 Buckets**: usar `force_destroy = true` no `aws_s3_bucket`
3. **CloudWatch Log Groups**: sÃ£o criados explicitamente no Terraform (nÃ£o auto-criados)
4. **Lambda Permissions**: definidas no mÃ³dulo que cria a integraÃ§Ã£o
5. **DynamoDB**: tabelas sÃ£o deletadas com destroy normalmente
6. **SQS**: filas sÃ£o deletadas com destroy normalmente
7. **API Gateway**: stages e routes sÃ£o deletados em cascata

### âš ï¸ NUNCA criar recursos manualmente no console AWS!
Se criar manualmente, o Terraform nÃ£o consegue destruir. Tudo DEVE estar no cÃ³digo.

---

## ğŸ“‹ Checklist para Criar um Novo Projeto

Quando eu pedir para criar um novo projeto, siga este fluxo:

### Pergunta Inicial ObrigatÃ³ria:

> **"Quais recursos AWS vocÃª pretende utilizar neste projeto?"**
> 
> OpÃ§Ãµes comuns:
> - ğŸ—„ï¸ **DynamoDB** â€” Banco NoSQL
> - âš¡ **Lambda** â€” FunÃ§Ãµes serverless (Python/Node)
> - ğŸŒ **API Gateway** â€” HTTP API para expor endpoints
> - ğŸ“¦ **S3** â€” Armazenamento de arquivos
> - ğŸ“¨ **SQS** â€” Filas de mensagens
> - ğŸ”” **SNS** â€” NotificaÃ§Ãµes
> - ğŸ‘¤ **Cognito** â€” AutenticaÃ§Ã£o de usuÃ¡rios
> - ğŸŒ **CloudFront** â€” CDN
> - ğŸ“… **EventBridge** â€” Agendamentos e eventos
> - ğŸ—ƒï¸ **RDS/Aurora** â€” Banco relacional
> - ğŸ³ **ECS/Fargate** â€” Containers
> - ğŸ”„ **Step Functions** â€” OrquestraÃ§Ã£o de workflows
> - ğŸ–¥ï¸ **Frontend** â€” React/Vite (Vercel)
>
> **Qual Ã© o nome do projeto?** (usado para: repo, tags, nomes de recursos)

### ApÃ³s a resposta, criar:

1. **Bucket S3 para state** (se ainda nÃ£o existir): `{nome-projeto}-terraform-state`
2. **Tabela DynamoDB para locks** (se ainda nÃ£o existir): `terraform-locks`
3. **RepositÃ³rio para cada recurso** com a estrutura padrÃ£o
4. **Arquivo `.code-workspace`** referenciando todos os repos
5. **README.md** em cada repo com instruÃ§Ãµes de deploy e destroy
6. **terraform.tfvars.example** para dev e prod em cada repo
7. **Atualizar este arquivo** `copilot-instructions.md` com o novo projeto

---

## ğŸ“¦ Templates por Recurso AWS

### DynamoDB

```hcl
# Exemplo de tabela padrÃ£o
resource "aws_dynamodb_table" "exemplo" {
  name           = "NomeTabela-${var.environment}"
  billing_mode   = var.billing_mode  # PAY_PER_REQUEST para dev, PROVISIONED para prod se necessÃ¡rio
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }

  # GSI para busca por usuÃ¡rio (padrÃ£o comum)
  attribute {
    name = "usuario_id"
    type = "S"
  }

  global_secondary_index {
    name            = "usuario_id-index"
    hash_key        = "usuario_id"
    projection_type = "ALL"
  }

  point_in_time_recovery {
    enabled = var.enable_pitr  # false em dev, true em prod
  }

  server_side_encryption {
    enabled = true
  }

  tags = {
    Name = "NomeTabela-${var.environment}"
  }
}
```

### Lambda (com Docker/ECR)

PadrÃ£o atual:
- **Runtime**: Python 3.11 via Docker image (`public.ecr.aws/lambda/python:3.11`)
- **Build**: Terraform `null_resource` com triggers automÃ¡ticos em `.py`, `requirements.txt`, `Dockerfile`
- **ECR**: `force_delete = true` para destroy limpo
- **Estrutura**: controller â†’ service â†’ repository (camadas separadas)
- **ValidaÃ§Ã£o**: Pydantic DTOs
- **Auth**: JWT customizado (ou Cognito se preferido)

### API Gateway

PadrÃ£o atual:
- **Tipo**: HTTP API v2 (`aws_apigatewayv2_api`)
- **IntegraÃ§Ã£o**: `AWS_PROXY` com Lambda
- **Route**: `$default` (catch-all, routing feito no Lambda)
- **CORS**: Configurado na API Gateway
- **Stage**: auto_deploy = true
- **Logs**: CloudWatch com formato JSON estruturado

### S3 (Template)

```hcl
resource "aws_s3_bucket" "exemplo" {
  bucket        = "${var.project_name}-{descritivo}-${var.environment}"
  force_destroy = true  # IMPORTANTE: permite destroy limpo

  tags = {
    Name = "${var.project_name}-{descritivo}-${var.environment}"
  }
}

resource "aws_s3_bucket_versioning" "exemplo" {
  bucket = aws_s3_bucket.exemplo.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "exemplo" {
  bucket = aws_s3_bucket.exemplo.id
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_public_access_block" "exemplo" {
  bucket                  = aws_s3_bucket.exemplo.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```

### SQS (Template)

```hcl
resource "aws_sqs_queue" "exemplo" {
  name                       = "${var.project_name}-{descritivo}-${var.environment}"
  message_retention_seconds  = 345600  # 4 dias
  visibility_timeout_seconds = 60
  receive_wait_time_seconds  = 10      # Long polling

  tags = {
    Name = "${var.project_name}-{descritivo}-${var.environment}"
  }
}

# Dead Letter Queue (recomendado)
resource "aws_sqs_queue" "exemplo_dlq" {
  name                      = "${var.project_name}-{descritivo}-dlq-${var.environment}"
  message_retention_seconds = 1209600  # 14 dias

  tags = {
    Name = "${var.project_name}-{descritivo}-dlq-${var.environment}"
  }
}

resource "aws_sqs_queue_redrive_policy" "exemplo" {
  queue_url = aws_sqs_queue.exemplo.id
  redrive_policy = jsonencode({
    deadLetterTargetArn = aws_sqs_queue.exemplo_dlq.arn
    maxReceiveCount     = 3
  })
}
```

---

## ğŸ”— Como Conectar Recursos Entre RepositÃ³rios

Os repositÃ³rios sÃ£o independentes. A conexÃ£o Ã© feita via **outputs â†’ tfvars**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    outputs.tf     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DynamoDB    â”‚ â”€â”€â”€â”€ ARNs â”€â”€â”€â”€â”€â–º â”‚   Lambda     â”‚
â”‚  repo        â”‚    table names   â”‚   repo       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                  function_arn
                                  function_name
                                       â”‚
                                       â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚ API Gateway  â”‚
                                  â”‚ repo         â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                  api_endpoint
                                       â”‚
                                       â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚  Frontend    â”‚
                                  â”‚  (.env)      â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo:

1. `terraform apply` no DynamoDB â†’ copiar ARNs/nomes do output
2. Colar nos `terraform.tfvars` do Lambda
3. `terraform apply` no Lambda â†’ copiar ARN/nome da funÃ§Ã£o do output
4. Colar nos `terraform.tfvars` do API Gateway
5. `terraform apply` no API Gateway â†’ copiar endpoint do output
6. Colar no `.env` do Frontend (`VITE_API_URL=...`)

---

## ğŸŒ Frontend

### PadrÃ£o Atual:

- **Framework**: React + Vite + TypeScript
- **Styling**: Tailwind CSS
- **Deploy**: Vercel
- **Config Vercel**: Root Directory = `controle_financeiro` (subpasta)
- **VariÃ¡vel de ambiente**: `VITE_API_URL` com endpoint do API Gateway

### Estrutura:

```
{nome-projeto}/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md  â† ESTE ARQUIVO
â”œâ”€â”€ .gitignore
â”œâ”€â”€ {subpasta-frontend}/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vercel.json
â”‚   â”œâ”€â”€ .env                     â† VITE_API_URL (NÃƒO versionar)
â”‚   â”œâ”€â”€ .env.example             â† Template (versionar)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.tsx
â”‚       â”œâ”€â”€ main.tsx
â”‚       â”œâ”€â”€ components/
â”‚       â”œâ”€â”€ hooks/
â”‚       â”œâ”€â”€ pages/
â”‚       â”œâ”€â”€ lib/
â”‚       â”‚   â””â”€â”€ api.ts           â† Chamadas HTTP ao API Gateway
â”‚       â””â”€â”€ styles/
â””â”€â”€ test-build.ps1               â† Script de validaÃ§Ã£o local
```

---

## ğŸ“Š Projeto de ReferÃªncia: Controlese

Este Ã© o projeto atual e serve como **exemplo vivo** da arquitetura:

| Recurso     | Repo / Pasta                             | Status |
|-------------|------------------------------------------|--------|
| DynamoDB    | `controlese-terraform/dynamodb`          | âœ… Ativo |
| Lambda      | `controlese-terraform/lambda`            | âœ… Ativo |
| API Gateway | `controlese-terraform/apigateway`        | âœ… Ativo |
| Frontend    | `controlese/controle_financeiro`         | âœ… Ativo (Vercel) |

### Tabelas DynamoDB:
- `Usuarios-{env}` (hash: `usuario_id`, GSI: `nome_usuario`)
- `Transacoes-{env}` (hash: `transacao_id`, GSI: `usuario_id`)
- `Categorias-{env}` (hash: `categoria_id`, GSI: `usuario_id`)
- `Subcategorias-{env}` (hash: `subcategoria_id`, GSI: `usuario_id`)
- `Cartoes-{env}` (hash: `cartao_id`, GSI: `usuario_id`)

### Lambda:
- FunÃ§Ã£o: `controlese-api-{env}`
- ECR: `controlese-api-{env}`
- Runtime: Python 3.11 (Docker)
- Camadas: controller â†’ service â†’ repository â†’ DynamoDB

### API Gateway:
- HTTP API v2: `controlese-api-{env}`
- Stage: `{env}` (auto-deploy)
- Route: `$default` (catch-all)
- CORS: configurado para Vercel domain

### AWS Account: `695284873308`
### Region: `us-east-1`
### State Bucket: `controlese-terraform-state`

---

## ğŸ§  Regras para o Agente (Aprendizado ContÃ­nuo)

### SEMPRE:

1. **Perguntar quais recursos AWS** antes de criar um novo projeto
2. **Seguir a estrutura de pastas** descrita neste documento
3. **Usar backend S3** com DynamoDB locks
4. **Separar dev e prod** com tfvars independentes
5. **Incluir `force_delete`/`force_destroy`** em recursos que suportam
6. **Criar README.md** com instruÃ§Ãµes de deploy E destroy
7. **Criar `.tfvars.example`** para dev e prod (sem secrets reais)
8. **Nomear recursos** com padrÃ£o: `{projeto}-{descritivo}-{env}`
9. **Tagear tudo** com: Environment, Project, ManagedBy, Repository
10. **Validar variÃ¡veis** com `validation {}` blocks no Terraform
11. **Documentar outputs** com descriptions claras
12. **Respeitar ordem de deploy** (dependÃªncias entre repos)
13. **Atualizar este arquivo** quando novos padrÃµes forem definidos

### NUNCA:

1. âŒ Criar recursos sem tags
2. âŒ Hardcodar account IDs, ARNs ou secrets no cÃ³digo
3. âŒ Misturar recursos de diferentes serviÃ§os AWS no mesmo repo
4. âŒ Versionar `terraform.tfvars` com secrets reais
5. âŒ Esquecer o `force_delete`/`force_destroy` em ECR, S3, etc.
6. âŒ Criar recursos manualmente no console AWS
7. âŒ Fazer deploy de prod sem antes testar em dev
8. âŒ Ignorar a ordem de destroy (pode causar dependÃªncias Ã³rfÃ£s)

### QUANDO EU PEDIR PARA:

- **"Criar novo projeto"** â†’ Perguntar recursos AWS + nome â†’ seguir checklist acima
- **"Adicionar novo recurso"** â†’ Criar novo repo com estrutura padrÃ£o â†’ atualizar workspace
- **"Fazer deploy"** â†’ Confirmar ambiente (dev/prod) â†’ seguir ordem de dependÃªncias
- **"Destruir tudo"** â†’ Confirmar ambiente â†’ seguir ordem INVERSA de destroy â†’ verificar que nada ficou
- **"Mudar algo no Lambda/API/DB"** â†’ Editar o repo correto â†’ plan â†’ apply
- **"Conectar recurso novo ao Lambda"** â†’ Criar IAM policy + env vars + tfvars

---

## ğŸ“ HistÃ³rico de DecisÃµes

| Data       | DecisÃ£o                                                      |
|------------|--------------------------------------------------------------|
| 2025-xx-xx | Estrutura multi-repo por recurso AWS criada (Controlese)     |
| 2025-xx-xx | Backend S3 + DynamoDB locks padronizado                      |
| 2025-xx-xx | Lambda com Docker/ECR como padrÃ£o (nÃ£o ZIP)                  |
| 2025-xx-xx | API Gateway HTTP v2 com catch-all route como padrÃ£o          |
| 2025-xx-xx | Frontend React+Vite+TS com deploy Vercel como padrÃ£o         |
| 2026-02-12 | DocumentaÃ§Ã£o de padrÃµes criada neste copilot-instructions.md |

---

> **Nota para o agente:** Este documento Ã© a sua fonte de verdade. Sempre que criar ou modificar
> infraestrutura, consulte estas instruÃ§Ãµes. Se algo novo for decidido durante uma conversa,
> proponha adicionar aqui para que o conhecimento persista entre sessÃµes.